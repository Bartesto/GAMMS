---
title: "Modelling seasonal vegetation data with GAMs"
author: "Bart Huntley"
date: "3 December 2015"
output: html_document
---

```{r, echo=FALSE, message=FALSE}
library(mgcv)
library(nlme)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(gridExtra)
# Functions
plotForecastErrors <- function(forecasterrors)
  {
     # make a histogram of the forecast errors:
     mybinsize <- IQR(forecasterrors)/4
     mysd   <- sd(forecasterrors)
     mymin  <- min(forecasterrors) - mysd*5
     mymax  <- max(forecasterrors) + mysd*3
     # generate normally distributed data with mean 0 and standard deviation mysd
     mynorm <- rnorm(10000, mean=0, sd=mysd)
     mymin2 <- min(mynorm)
     mymax2 <- max(mynorm)
     if (mymin2 < mymin) { mymin <- mymin2 }
     if (mymax2 > mymax) { mymax <- mymax2 }
     # make a red histogram of the forecast errors, with the normally distributed data overlaid:
     mybins <- seq(mymin, mymax, mybinsize)
     hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
     # freq=FALSE ensures the area under the histogram = 1
     # generate normally distributed data with mean 0 and standard deviation mysd
     myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
     # plot the normal curve as a blue line on top of the histogram of forecast errors:
     points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
```

First up we are going to load in Dirk Hartog Island (DHI) vegetation data for the period 1987 to 2015. This data comes from freely downloaded [USGS Landsat data](http://glovis.usgs.gov/) that has been top of atmosphere corrected to enable between date comparison. This data has been converted to percentage vegetation cover through the modelling of on-ground assessed vegetation cover with spectral band indices. The data is then summarised to monthly observations to make the time series regular. Please note that due to different overpass schedules of the different Landsat sensors, errors in satellite sensors, decommissioning of older Landsat sensors and cloud cover it has been necessary to interpolate between some months to construct a regular time series.

```{r}
dveg <- read.csv("GAMM_month_interp_mtsd.csv", header = TRUE, stringsAsFactors = FALSE)
dveg <- dveg[,-1] # remove 1st column of row numbers

# Create an individual data frame for each site
for(i in 1:length(names(dveg))-1){
        d <- dveg[, c(1, 1 + i)]
        d$date <- as.Date(d$date, "%Y-%m-%d")
        name <- names(d)[2]
        d$site <- name
        names(d)[2] <- "veg"
        assign(paste0("d_", name), d)
}
```

## Modelling with GAMs
*This modelling has been adapted from work by* [Gavin Simpson](http://www.fromthebottomoftheheap.net/2014/05/09/modelling-seasonal-data-with-gam/)

In this work we will assess for any trend or long term change in the vegetation on DHI taking into account any seasonal or within year change. Essentially our model will look like: $$y = \beta_0 + f_s \left( x_1 \right) + f_t \left( x_2 \right) + \epsilon$$

where $\beta_0$ is the intercept, $f_s$ and $f_t$ are smooth functions for the seasonal and trend features. The $x_1$ and the $x_2$ are covariate time indicators for season (number version of the month) and year (essentially the date converted to a number).

It is important to note that this trend plus seasonal model is purely additive in that the seasonal component for any given month will be the same throughout the time series.

From here we will take one site (dhi_01) and begin the data preparation.
```{r}
df <- d_dhi_01
df <- df %>%
        mutate(nMonth = month(date), Month = month.abb[nMonth], 
               Year = year(date), Time = as.numeric(date) / 100)
df <- df[with(df, order(date)), ]
```

Firstly we will visualise the time series as has previously been shown in reports with a fixed y scale that hides a good deal of the variation followed by another plot whereby the y scale is set by the range of the data. 
```{r, echo=FALSE, message=FALSE}
p1 <- ggplot(df, aes(x = date, y = veg)) +
        geom_point() +
        geom_line() +
        theme_bw() +
        ggtitle("Site dhi_01") +
        ylab("vegetation %") +
        ylim(c(0, 80))
p1
ylim <- with(df, range(veg))
p2 <- ggplot(df, aes(x = date, y = veg)) +
        geom_point() +
        geom_line() +
        theme_bw() +
        ggtitle("Site dhi_01") +
        ylab("vegetation %") +
        ylim(ylim)
p2

```

Initially we will use a naive model, not taking into account any correlation that appears to be present.
```{r}
m <- gamm(veg ~ s(nMonth, bs = "cc", k = 12) + s(Time),
          data = df)

summary(m$gam)
```

The model appears to be significant and account for 72% of the variation in the data. Looking at some diagnostic plots however, shows we need to account for corellation.

```{r, echo=FALSE}
layout(matrix(1:4, ncol = 2))
plot(m$gam, scale = 0)
acf(resid(m$lme), lag.max = 36, main = "ACF")
pacf(resid(m$lme), lag.max = 36, main = "pACF")
layout(1)
```

The ACF plot shows effects at least out to the third lag and the plot over Time (the yearly trend) is overly wiggly indicating possible overfitting. The smooth terms in this model are not dealing with the correlation.

Next we will create three AR(p) models and assess them against each other. Note "cc" denotes a cyclic cubic spline meaning the beginning and end of a month will link up. Also the correlation term is nested within each year.
```{r, message=FALSE}
ctrl <- list(niterEM = 0, msVerbose = FALSE, optimMethod="L-BFGS-B")
# AR(1)
m1 <- gamm(veg ~ s(nMonth, bs = "cc", k = 12) + s(Time, k = 20),
          data = df, correlation = corARMA(form = ~ 1|Year, p = 1),
          control = ctrl)

# AR(2)
m2 <- gamm(veg ~ s(nMonth, bs = "cc", k = 12) + s(Time, k = 20),
           data = df, correlation = corARMA(form = ~ 1|Year, p = 2),
           control = ctrl)

# AR(3)
m3 <- gamm(veg ~ s(nMonth, bs = "cc", k = 12) + s(Time, k = 20),
           data = df, correlation = corARMA(form = ~ 1|Year, p = 3),
           control = ctrl)

anova(m$lme, m1$lme, m2$lme, m3$lme)
```

Looking at the output of the anova test the AIC, BIC and p-value all suggest that AR(1) model is the best and this is also shown in an ACF plot whereby the majority of autocorrelation has shown to be dealt with. The trend over time is still wiggly but has been further smoothed.
```{r, echo=FALSE}
layout(matrix(1:4, ncol = 2))
plot(m1$gam, scale = 0)
res <- resid(m1$lme, type = "normalized")
acf(res, lag.max = 36, main = "ACF - AR(1) errors")
pacf(res, lag.max = 36, main = "pACF- AR(1) errors")
layout(1)
```

A look at the residuals indicates that the model errors are centred on zero and normally distributed.
```{r}
plotForecastErrors(resid(m1$lme))
```

Now we will extract the model terms over the time series period and plot it over the original data. Note the data has been centred by subtracting the mean.
```{r}
want <- seq(1, nrow(df), length.out = 200) # evenly spaced sequence of points
pdat <- with(df,
             data.frame(Time = Time[want], Date = date[want],
                        nMonth = nMonth[want])) # new predictions data frame
p1 <- predict(m1$gam, newdata = pdat, type = "terms", se.fit = TRUE)
## combine with the predictions data, including fitted and SEs
pdat <- transform(pdat, p1 = p1$fit[,2], se1 = p1$se.fit[,2])
```

```{r, echo=FALSE}
ggplot(df, aes(x = date, y = veg - mean(veg))) +
        geom_point() +
        geom_line() +
        theme_bw() +
        geom_line(data = pdat, aes(x = Date, y = p1), stat = "identity", 
                  colour = "blue")
summary(m1$gam)
```


The above plot looks reasonable and the model summary shows that the smooth terms are significant with the model still accounting for 72% of the variation. 

Next we will look at identifying periods of statistically significant change in the time series. To do this we will find the instantaneous rate of change, represented by the slope of the regression line at any point on the line. This can be determined from the first derivitive and the method of finite differences. To do this we can approximate the first derivitive of the fitted spline by choosing a set of points on the function and a second set of points located located a very small distance from the first. Confidence intervals are calculated using some functions written by [Gavin Simpson](http://www.fromthebottomoftheheap.net/2014/05/15/identifying-periods-of-change-with-gams/).
```{r}
df.res <- df.residual(m1$gam)
crit.t <- qt(0.025, df.res, lower.tail = FALSE)
pdat <- transform(pdat,
                  upper = p1 + (crit.t * se1),
                  lower = p1 - (crit.t * se1))

tmpf <- tempfile()
download.file("https://gist.github.com/gavinsimpson/e73f011fdaaab4bb5a30/raw/82118ee30c9ef1254795d2ec6d356a664cc138ab/Deriv.R",
              tmpf)
source(tmpf)


Term <- "Time"
m1.d <- Deriv(m1)
m1.dci <- confint(m1.d, term = Term)
m1.dsig <- signifD(pdat$p1, d = m1.d[[Term]]$deriv,
                   m1.dci[[Term]]$upper, m1.dci[[Term]]$lower)
```

With this out of the way we can plot up the time series and colour up as red any sections of the time series as a significant decline and blue as any sections of significant gain. P-value is set at 0.05.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
ggplot(df, aes(x = date, y = veg - mean(veg))) +
        geom_point(colour = "light grey") +
        geom_line(colour = "light grey") +
        theme_bw() +
        geom_line(data = pdat, aes(x = Date, y = p1), stat = "identity", 
                  colour = "black") +
        geom_line(data = pdat, aes(x = Date, y = upper), stat = "identity", 
                  colour = "black", linetype = 2) +
        geom_line(data = pdat, aes(x = Date, y = lower), stat = "identity", 
                  colour = "black", linetype = 2) +
        geom_line(data = pdat, aes(x = Date, y = unlist(m1.dsig$incr)), stat = "identity", 
                  colour = "blue", size = 1.5) +
        geom_line(data = pdat, aes(x = Date, y = unlist(m1.dsig$decr)), stat = "identity", 
                  colour = "red", size = 1.5) 
        
```

## Spline interactions

Now we will set up a model that allows the seasonal component to change in time along with the overall trend. The new model will take the form of: $$y = \beta_0 + f \left( x_1, x_2 \right) + \epsilon$$

Note that $f\left(\right)$ is now a smooth term over both time variables and is a tensor product smooth. The within year variable will be the numeric month and the time variable will now just be the calendar year. The knots will also change for the within year period. Previoulsy they were 1 to 12 however that meant that the end of December would be the same as the beginning of January. By extending the knots from 0.5 to 12.5 (just beyond the month), it makes the distance between December and January the same as any other month.

Again we will begin with a naive model, not taking into account any auocorrelation. We will plot the ACF to assess.
```{r}
knots <- list(nMonth = c(0.5, seq(1, 12, length = 10), 12.5))
nm <- gamm(veg ~ te(Year, nMonth, bs = c("cr","cc"), k = c(10,12)),
           data = df, method = "REML", knots = knots)
plot(acf(resid(nm$lme, type = "normalized")))


```

We see lingering correlations out to 3 lags and some more from lag 10 and beyond. A number of AR(p) models will be calculated and assessed.
```{r, cache=TRUE}
ctrl <- list(niterEM = 0, optimMethod="L-BFGS-B", maxIter = 100, msMaxIter = 100)

for (i in 1:4) {
        m <- gamm(veg ~ te(Year, nMonth, bs = c("cr","cc"), k = c(10,12)),
                   data = df, method = "REML", control = ctrl, knots = knots,
                   correlation = corARMA(form = ~ 1 | Year, p = i))
        assign(paste0("nm", i), m) 
}

anova(nm$lme, nm1$lme, nm2$lme, nm3$lme, nm4$lme)
plot(acf(resid(nm1$lme, type = "normalized")))
summary(nm1$gam)
```

From the above, the first model with a nested correlation function (nm1) accounts for the correlations, has the lowest AIC and BIC scores and a significant p value. The model accounts for 58% of the variation in the data. As the following graph shows, the errors also appear to be normally distributed and centred on zero.
```{r}
plotForecastErrors(resid(nm1$lme))
```

Next we can look at the seasonal change between different years.
```{r}
npdat <- with(df,
             data.frame(Year = rep(c(1990, 2014), each = 100),
                        nMonth = rep(seq(1, 12, length = 100), times = 2)))

pred <- predict(nm1$gam, newdata = npdat, se.fit = TRUE)
crit <- qt(0.975, df = df.residual(nm1$gam)) # ~95% interval critical t
npdat <- transform(npdat, fitted = pred$fit, se = pred$se.fit, fYear = as.factor(Year))
npdat <- transform(npdat,
                  upper = fitted + (crit * se),
                  lower = fitted - (crit * se))


```

```{r, echo=FALSE}
p3 <- ggplot(npdat, aes(x = nMonth, y = fitted, group = fYear)) +
        geom_ribbon(mapping = aes(ymin = lower, ymax = upper,
                                  fill = fYear), alpha = 0.2) + # confidence band
        geom_line(aes(colour = fYear)) +    # predicted temperatures
        theme_bw() +                        # minimal theme
        theme(legend.position = "top") +    # push legend to the top
        labs(y = "vegetation %", x = NULL) +
        scale_fill_discrete(name = "Year") + # correct legend name
        scale_colour_discrete(name = "Year") +
        scale_x_continuous(breaks = 1:12,   # tweak where the x-axis ticks are
                           labels = month.abb, # & with what labels
                           minor_breaks = NULL)
p3
```



